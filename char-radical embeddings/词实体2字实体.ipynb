{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-*-coding:utf-8-*-\n",
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')\n",
    "import codecs\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zero_digits(s):\n",
    "    \"\"\"\n",
    "    Replace every digit in a string by a zero.\n",
    "    \"\"\"\n",
    "    s[0] = re.sub('\\d', '0', s[0])\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tag(t):\n",
    "    if '-' not in t:\n",
    "        return 'O'\n",
    "    else:\n",
    "        return t.split('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tag_scheme:IOBES\n",
    "def get_sentence(sent, word):\n",
    "    tag = get_tag(word[-1])\n",
    "    ws = ' '.join(word[0]).split()\n",
    "    if tag == 'O':\n",
    "        for elem in ws:\n",
    "            sent.append([elem, word[1], tag])\n",
    "    elif tag[0] == 'S':\n",
    "        if len(word[0]) == 1:\n",
    "            sent.append([word[0], word[1], word[2]])\n",
    "        else:\n",
    "            sent.append([ws[0], word[1], 'B-' + tag[1]])\n",
    "            for _w in ws[1:-1]:\n",
    "                sent.append([_w, word[1], 'I-' + tag[1]])\n",
    "            sent.append([ws[-1], word[1], 'E-' + tag[1]])\n",
    "    elif tag[0] == 'I':\n",
    "        for _w in ws:\n",
    "            sent.append([_w, word[1], 'I-' + tag[1]])\n",
    "    elif tag[0] == 'B':\n",
    "        sent.append([ws[0], word[1], 'B-' + tag[1]])\n",
    "        for _w in ws[1:]:\n",
    "            sent.append([_w, word[1], 'I-' + tag[1]])\n",
    "    else: \n",
    "        if len(word[0]) == 1:\n",
    "            sent.append([word[0], word[1], word[2]])\n",
    "        else:\n",
    "            for _w in ws[:-1]:\n",
    "                sent.append([_w, word[1], 'I-' + tag[1]])\n",
    "            sent.append([ws[-1], word[1], 'E-' + tag[1]])\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entity2char(path):\n",
    "    sentences = []\n",
    "    sentence = []\n",
    "    for line in codecs.open(path, 'r', 'utf8'):\n",
    "        if not line.rstrip():\n",
    "            if len(sentence) > 0:\n",
    "                if 'DOCSTART' not in sentence[0][0]:\n",
    "                    sentences.append(sentence)\n",
    "                sentence = []\n",
    "        else:\n",
    "            #zero_digits(line.rstrip().split()) if zeros else \n",
    "            word = line.rstrip().split()\n",
    "            assert len(word) >= 2\n",
    "            get_sentence(sentence, word)\n",
    "    if len(sentence) > 0:\n",
    "        if 'DOCSTART' not in sentence[0][0]:\n",
    "            sentences.append(sentence)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_char_tags(path, sentences):\n",
    "    fw = codecs.open(path, 'w', encoding = 'utf-8')\n",
    "    for sent in sentences:\n",
    "        for elems in sent:\n",
    "            fw.write(' '.join(elems) + '\\n')\n",
    "        fw.write('\\n')\n",
    "    fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PER:P, LOC:L, ORG: G, O\n",
    "zeros = 1\n",
    "#tag_scheme = ['O','S-ORG', 'B1-ORG', 'B2-ORG', 'I-ORG', 'E-ORG']\n",
    "infile = './dev_after.txt'\n",
    "sentences = entity2char(infile)\n",
    "\n",
    "outfile = './dev_charset.txt'\n",
    "write_char_tags(outfile, sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "radical_path = './jian_char_radicals.txt'\n",
    "\n",
    "radicals = {}\n",
    "for line in codecs.open(radical_path, 'r', encoding = 'utf-8'):\n",
    "    t = line.strip().split(':')\n",
    "    radicals[t[0]] = t[-1].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dico(item_list):\n",
    "    \"\"\"\n",
    "    Create a dictionary of items from a list of list of items.\n",
    "    \"\"\"\n",
    "    assert type(item_list) is list\n",
    "    dico = {}\n",
    "    for items in item_list:\n",
    "        for item in items:\n",
    "            if item not in dico:\n",
    "                dico[item] = 1\n",
    "            else:\n",
    "                dico[item] += 1\n",
    "    return dico\n",
    "\n",
    "def create_mapping(dico):\n",
    "    \"\"\"\n",
    "    Create a mapping (item to ID / ID to item) from a dictionary.\n",
    "    Items are ordered by decreasing frequency.\n",
    "    \"\"\"\n",
    "    sorted_items = sorted(dico.items(), key=lambda x: (-x[1], x[0]))\n",
    "    id_to_item = {i: v[0] for i, v in enumerate(sorted_items)}\n",
    "    item_to_id = {v: k for k, v in id_to_item.items()}\n",
    "    return item_to_id, id_to_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def char_mapping(sentences):\n",
    "    \"\"\"\n",
    "    Create a dictionary and a mapping of chars, sorted by frequency.\n",
    "    \"\"\"\n",
    "    chars = [[x[0] for x in s] for s in sentences]\n",
    "    dico = create_dico(chars)\n",
    "    dico['<UNK>'] = 10000000\n",
    "    char_to_id, id_to_char = create_mapping(dico)\n",
    "    print \"Found %i unique chars (%i in total)\" % (\n",
    "        len(dico), sum(len(x) for x in chars)\n",
    "    )\n",
    "    return dico, char_to_id, id_to_char\n",
    "\n",
    "def radical_mapping(sentences, radicals):\n",
    "    \"\"\"\n",
    "    Create a dictionary and a mapping of radicals, sorted by frequency.\n",
    "    \"\"\"\n",
    "\n",
    "    rads = [\"\".join([\"\".join(radicals[x[0]]) for x in s if x[0] in radicals]) for s in sentences]\n",
    "    dico = create_dico(rads)\n",
    "    radical_to_id, id_to_radical = create_mapping(dico)\n",
    "    print \"Found %i unique radicals (%i in total)\" % (\n",
    "        len(dico), sum(len(x) for x in rads))\n",
    "    return dico, radical_to_id, id_to_radical\n",
    "\n",
    "def tag_mapping(sentences):\n",
    "    \"\"\"\n",
    "    Create a dictionary and a mapping of tags, sorted by frequency.\n",
    "    \"\"\"\n",
    "    tags = [[word[-1] for word in s] for s in sentences]\n",
    "    dico = create_dico(tags)\n",
    "    tag_to_id, id_to_tag = create_mapping(dico)\n",
    "    print \"Found %i unique named entity tags\" % len(dico)\n",
    "    return dico, tag_to_id, id_to_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dico_chars, char_to_id, id_to_char = char_mapping(sentences)\n",
    "dico_chars_train = dico_chars\n",
    "\n",
    "radical_path = '/Users/wangwenhui/Desktop/论文/NER/FOFE_charembeddings_radicalembeddings/数据/char_radicals.txt'\n",
    "radicals_dict = {}\n",
    "for line in codecs.open(radical_path, 'r', encoding = 'utf-8'):\n",
    "    tmp = line.strip().split(\":\")\n",
    "    radicals_dict[tmp[0]] = tmp[-1].split()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dico_radicals, radical_to_id, id_to_radical = radical_mapping(sentences, radicals_dict)\n",
    "\n",
    "\n",
    "dico_tags, tag_to_id, id_to_tag = tag_mapping(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(sentences, char_to_id, radical_to_id, tag_to_id, radicals_dict,lower=False):\n",
    "    \"\"\"\n",
    "    Prepare the dataset. Return a list of lists of dictionaries containing:\n",
    "        - char indexes\n",
    "        - radical indexes\n",
    "        - tag indexes\n",
    "    \"\"\"\n",
    "\n",
    "    data = []\n",
    "    for s in sentences:\n",
    "        str_chars = [w[0] for w in s]\n",
    "        chars = [char_to_id[w if w in char_to_id else '<UNK>']\n",
    "                 for w in str_chars]\n",
    "        radicals = []\n",
    "        for c in str_chars:\n",
    "            if c in radicals_dict:\n",
    "                tmp = []\n",
    "                for r in radicals_dict[c]:\n",
    "                    if r in radical_to_id:\n",
    "                        tmp.append(radical_to_id[r]) \n",
    "                radicals.append(tmp)   \n",
    "\n",
    "\n",
    "        tags = [tag_to_id[w[-1]] for w in s]\n",
    "        data.append({\n",
    "            'str_chars': str_chars,\n",
    "            'chars': chars,\n",
    "            'radicals': radicals,\n",
    "            'tags': tags\n",
    "        })\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = prepare_dataset(sentences, char_to_id, radical_to_id, tag_to_id, radicals_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "808"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in radicals_dict[u'\\u535e']:\n",
    "    print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
